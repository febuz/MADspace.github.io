{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DEFINITIONS.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/febuz/MADspace.github.io/blob/master/DEFINITIONS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "wwfUP9Xkobvz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#DEFINITIONS\n",
        "Here we developed the \n",
        "\n",
        "-OLS Regression \n",
        "\n",
        "-Correlation functions (preparation AR models)\n",
        "\n",
        "-Candlestick definitions\n",
        "\n",
        "-Augmented Dickey Fuller stationair test \n",
        "\n",
        "for JHTALIB\n",
        "#Regression\n",
        "Regression formula:\n",
        "\n",
        "Source: https://en.wikipedia.org/wiki/Autoregressive_model\n",
        "\n",
        "Source: https://www.fmlabs.com/reference/RegressionLineMv.htm\n",
        "\n",
        "Source: https://github.com/statsmodels/statsmodels/\n",
        "\n",
        "#Ordinairy Least Squares Regression\n",
        "1. check the stationality of the time series \n",
        "2. test the stationality of the data\n",
        "\n",
        "    a) Dickey-Fuller test for unit root\n",
        "    \n",
        "    b) Augmented Dickey-Fuller (ADF) test for unit root\n",
        "3. only use stationairy series for your model, normalize or standardize other wise \n",
        "4. Basis OLS model: \n",
        "\n",
        "y = mx + b\n",
        "\n",
        "y = how far up\n",
        "\n",
        "x = how far along\n",
        "\n",
        "m = Slope or Gradient (how steep the line is)\n",
        "\n",
        "b = the Y Intercept (where the line crosses the Y axis)\n",
        "\n",
        "5. find the line of best fit for a group of (x,y) points:\n",
        "\n",
        "Step 1:\tFor each (x,y) calculate x2 and xy\n",
        "\n",
        "Step 2:\tSum all x, y, x2 and xy, which gives us Σx, Σy, Σx2 and Σxy (Σ means \"sum up\")\n",
        "\n",
        "Step 3:\tCalculate Slope m:\n",
        "\n",
        "m = (N(Σxy) − (Σx) (Σy))/(N(Σx^2) − (Σx)^2)\n",
        "\n",
        "(N is the number of points.)\n",
        "\n",
        "Step 4:\tCalculate Intercept a:\n",
        "\n",
        "a = (Σy) - b(Σx)\n",
        "\n",
        "Step 5: Assemble the equation of a line\n",
        "\n",
        "y = mx + a\n",
        "\n",
        "Source: https://www.mathsisfun.com/data/least-squares-regression.html\n",
        "#Moving Average (MA)\n",
        "Source: https://en.wikipedia.org/wiki/Moving-average_model\n",
        "#Least Squares Regression vs Autoregression (AR)\n",
        "What is the difference between Least Squares Regression and Autoregression (AR)?\n",
        "\n",
        "Source: https://machinelearningmastery.com/autoregression-models-time-series-forecasting-python/ \n"
      ]
    },
    {
      "metadata": {
        "id": "o6wnz_kaAN_l",
        "colab_type": "code",
        "outputId": "6efc73c1-3b73-4970-9436-afbda5512233",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install --upgrade jhtalib\n",
        "apikey = 'Apikey 9fa3addd7c29c1da3a51de2d10628c4d6c3747e2577c79ea047a85068708d66f'\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: jhtalib in /usr/local/lib/python3.6/dist-packages (20190319.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xsqFge3ZkiIs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "from pandas import Series\n",
        "from pandas import DataFrame\n",
        "from pandas import concat\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot\n",
        "#series = roc_list #Series.from_csv('EHV_HP.csv', header=0)\n",
        "d = {'l': roc_list[-20:]}\n",
        "#values = DataFrame(data=d)\n",
        "df = pd.DataFrame(data=d)\n",
        "\n",
        "#values = Series(roc_list)\n",
        "dataframe = concat([df.shift(1), df], axis=1)\n",
        "#dataframe.columns = ['t-1', 't+1']\n",
        "#result = dataframe.corr()\n",
        "#print(result)\n",
        "from pandas import Series\n",
        "from matplotlib import pyplot\n",
        "from statsmodels.graphics.tsaplots import plot_acf\n",
        "#series = Series.from_csv('daily-minimum-temperatures.csv', header=0)\n",
        "plot_acf(df, lags=11)\n",
        "#autocorrelation_plot(values)\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7RmuuM8bpdAi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Interpretation: With this data we could estimate a model with AR(4)\n",
        "PAC(4)"
      ]
    },
    {
      "metadata": {
        "id": "JYXhHX3NP70-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Linear Regression 2 different calculations (LSR and SLR) with 2 different outcomes. And calculation of AR. Can you check the AR output?\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "83Et3cHcUfpV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from datetime import datetime as dt\n",
        "from pprint import pprint as pp\n",
        "import matplotlib.dates as mdates\n",
        "import matplotlib.pyplot as plt\n",
        "import jhtalib as jhta\n",
        "\n",
        "import numpy\n",
        "\n",
        "\n",
        "def autocorr1(x,lags):\n",
        "    '''numpy.corrcoef, partial'''\n",
        "\n",
        "    corr=[1. if l==0 else numpy.corrcoef(x[l:],x[:-l])[0][1] for l in lags]\n",
        "    return numpy.array(corr)\n",
        "\n",
        "def autocorr2(x,lags):\n",
        "    '''manualy compute, non partial'''\n",
        "\n",
        "    mean=numpy.mean(x)\n",
        "    var=numpy.var(x)\n",
        "    xp=x-mean\n",
        "    corr=[1. if l==0 else numpy.sum(xp[l:]*xp[:-l])/len(x)/var for l in lags]\n",
        "\n",
        "    return numpy.array(corr)\n",
        "\n",
        "def autocorr3(x,lags):\n",
        "    '''fft, pad 0s, non partial'''\n",
        "\n",
        "    n=len(x)\n",
        "    # pad 0s to 2n-1\n",
        "    ext_size=2*n-1\n",
        "    # nearest power of 2\n",
        "    fsize=2**numpy.ceil(numpy.log2(ext_size)).astype('int')\n",
        "\n",
        "    xp=x-numpy.mean(x)\n",
        "    var=numpy.var(x)\n",
        "\n",
        "    # do fft and ifft\n",
        "    cf=numpy.fft.fft(xp,fsize)\n",
        "    sf=cf.conjugate()*cf\n",
        "    corr=numpy.fft.ifft(sf).real\n",
        "    corr=corr/var/n\n",
        "\n",
        "    return corr[:len(lags)]\n",
        "\n",
        "def autocorr4(x,lags):\n",
        "    '''fft, don't pad 0s, non partial'''\n",
        "    mean=x.mean()\n",
        "    var=numpy.var(x)\n",
        "    xp=x-mean\n",
        "\n",
        "    cf=numpy.fft.fft(xp)\n",
        "    sf=cf.conjugate()*cf\n",
        "    corr=numpy.fft.ifft(sf).real/var/len(x)\n",
        "\n",
        "    return corr[:len(lags)]\n",
        "\n",
        "def autocorr5(x,lags):\n",
        "    '''numpy.correlate, non partial'''\n",
        "    mean=x.mean()\n",
        "    var=numpy.var(x)\n",
        "    xp=x-mean\n",
        "    corr=numpy.correlate(xp,xp,'full')[len(x)-1:]/var/len(x)\n",
        "\n",
        "    return corr[:len(lags)]\n",
        "\n",
        "\n",
        "def testcor():\n",
        "\n",
        "    y=[0, 2, 1, 3, 2, 4, 3, 5, 4, 6]\n",
        "    \n",
        "    y=numpy.array(y).astype('float')\n",
        "\n",
        "    lags=range(2)\n",
        "    fig,ax=plt.subplots()\n",
        "\n",
        "    for funcii, labelii in zip([autocorr1, autocorr2, autocorr3, autocorr4,\n",
        "        autocorr5], ['np.corrcoef, partial', 'manual, non-partial',\n",
        "            'fft, pad 0s, non-partial', 'fft, no padding, non-partial',\n",
        "            'np.correlate, non-partial']):\n",
        "\n",
        "        cii=funcii(y,lags)\n",
        "        print(labelii)\n",
        "        print(cii)\n",
        "        ax.plot(lags,cii,label=labelii)\n",
        "\n",
        "    ax.set_xlabel('lag')\n",
        "    ax.set_ylabel('correlation coefficient')\n",
        "    ax.legend()\n",
        "    plt.show()\n",
        "\n",
        "testcor()\n",
        "\n",
        "def ACF():\n",
        "  \"\"\"\n",
        "  Auto Correlation Function\n",
        "  \"\"\"\n",
        "\n",
        "def PACF():\n",
        "  \"\"\"\n",
        "  Partial Auto Correlation Function\n",
        "  \"\"\"\n",
        "\n",
        "\n",
        "y=[0, 2, 1, 3, 2, 4, 3, 5, 4, 6]\n",
        "y0=y[2:10]\n",
        "y1=y[1:9]\n",
        "y2=y[0:8]\n",
        "    \n",
        "cory0y1=jhta.COR(y0,y1)\n",
        "pp ('cory0y1')\n",
        "pp(cory0y1)\n",
        "cory1y2=jhta.COR(y1,y2)\n",
        "pp ('cory1y2')\n",
        "pp(cory1y2)\n",
        "cory2y0=jhta.COR(y2,y0)\n",
        "pp ('cory2y0')\n",
        "pp(cory2y0)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SbSgpmkiFZdF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Smoothing\n",
        "Finanicial hacker\n",
        "\n",
        "Source: https://www.financial-hacker.com/trend-delusion-or-reality/\n",
        "We can use the result of the pacf (the amount of partial correlation function lags with predictive value) to input as smoothing period or the trend\n",
        "\n",
        "#Relative Volatility Index (RVI) (see below: rvi original)\n",
        "\n",
        "#Relative Volatility Index Smoothed (RVIS)\n",
        "Because most indicators measure price change, Dorsey developed the RVI as a confirming indicator that measures the direction of volatility. It is almost identical to the Relative Strength Index (RSI) but uses the standard deviation of high and low prices.\n",
        "\n",
        "How To Calculate the Relative Volatility Index Smoothed (RVIS) using EMA\n",
        "RVI = 100 * U / (U + D)\n",
        "Where:\n",
        "U = EMA(N*2)-1,N of USD\n",
        "D = EMA(N*2)-1,N of DSD\n",
        "USD = If close > close(1) then SD,S else 0\n",
        "DSD = If close < close(1) then SD,S else 0\n",
        "S = User selected period for the Standard Deviation of the close (Dorsey suggested 10).\n",
        "N = User selected smoothing period (Dorsey suggested 14)\n",
        "(Instead of using Wilder’s Smoothing **we use an EMA** with a period of (N*2)-1 which produces the same result but is faster to calculate.)\n",
        "\n",
        "Source: http://etfhq.com/blog/2011/02/16/relative-volatility-index/\n",
        "\n",
        "The Inertia indicator is plotted on a scale of 0 to 100 and its middle level of 50 acts as a threshold separating uptrends from downtrends.\n",
        "\n",
        "Source: http://www.binarytribune.com/forex-trading-indicators/inertia-indicator/\n",
        "\n",
        "#Inertia\n",
        "Donald Dorsey (Stocks & Commodities , V.13:9 (September, 1995): \"Refining the Relative Volatility Index\")\n",
        "//@version=3\n",
        "// Copyright (c) 2019-present, Alex Orekhov (everget)\n",
        "// Dorsey Inertia script may be freely distributed under the MIT license.\n",
        "study(\"Dorsey Inertia\", shorttitle=\"Inertia\")\n",
        "\n",
        "stdevLength = input(title=\"Standard Deviation Length\", type=integer, defval=21)\n",
        "rviSmoothLength = input(title=\"RVI Smoothing Length\", type=integer, defval=14)\n",
        "smoothLength = input(title=\"Inertia Smoothing Length\", type=integer, defval=14)\n",
        "\n",
        "#RVI original\n",
        "// Relative Volatility Index (1993)\n",
        "rviOriginal(src, stdevLength, smoothLength) =>\n",
        "\tstdev = stdev(src, stdevLength)\n",
        "\tupSum = ema(change(src) >= 0 ? stdev : 0, smoothLength)\n",
        "\tdownSum = ema(change(src) >= 0 ? 0 : stdev, smoothLength)\n",
        "\t100 * upSum / (upSum + downSum)\n",
        "\n",
        "rvi = avg(rviOriginal(high, stdevLength, rviSmoothLength), rviOriginal(low, stdevLength, rviSmoothLength))\n",
        "inertia = linreg(rvi, smoothLength, 0)\n",
        "\n",
        "inertiaColor = inertia > 50 ? #0ebb23 : red\n",
        "\n",
        "plot(inertia, title=\"Inertia\", linewidth=2, color=inertiaColor, transp=0)\n",
        "hline(50, title=\"Middle Level\", linestyle=dotted)\n",
        "\n",
        "Source: https://www.tradingview.com/script/bzxmXFGd-Dorsey-Inertia/\n",
        "\n",
        "////////////////////////////////////////////////////////////\n",
        "//  Copyright by HPotter v1.0 23/05/2017\n",
        "// The inertia indicator measures the market, stock or currency pair momentum and \n",
        "// trend by measuring the security smoothed RVI (Relative Volatility Index). \n",
        "// The RVI is a technical indicator that estimates the general direction of the \n",
        "// volatility of an asset.\n",
        "// The inertia indicator returns a value that is comprised between 0 and 100. \n",
        "// Positive inertia occurs when the indicator value is higher than 50. As long as \n",
        "// the inertia value is above 50, the long-term trend of the security is up. The inertia \n",
        "// is negative when its value is lower than 50, in this case the long-term trend is \n",
        "// down and should stay down if the inertia stays below 50.\n",
        "////////////////////////////////////////////////////////////\n",
        "study(title=\"Inertia Indicator\", shorttitle=\"Inertia\")\n",
        "Period = input(10, minval=1)\n",
        "Smooth = input(14, minval=1)\n",
        "hline(50, color=green, linestyle=line)\n",
        "xPrice = close\n",
        "StdDev = stdev(xPrice, Period)\n",
        "d = iff(close > close[1], 0, StdDev)\n",
        "u = iff(close > close[1], StdDev, 0)\n",
        "nU = (13 * nz(nU[1],0) + u) / 14\n",
        "nD = (13 * nz(nD[1],0) + d) / 14\n",
        "nRVI = 100 * nU / (nU + nD)\n",
        "nRes = ema(nRVI, Smooth)\n",
        "plot(nRes, color=red, title=\"Inertia\")\n",
        "\n",
        "Source: https://www.tradingview.com/script/JKJGpmuX-Inertia-Indicator/\n",
        "\n",
        "#RVI and MACD\n",
        "https://www.researchgate.net/profile/Dejan_Eric/publication/228820374_Application_of_MACD_and_RVI_indicators_as_functions_of_investment_strategy_optimization_on_the_financial_market/links/546d40b40cf2193b94c58100/Application-of-MACD-and-RVI-indicators-as-functions-of-investment-strategy-optimization-on-the-financial-market.pdf?origin=publication_detail"
      ]
    },
    {
      "metadata": {
        "id": "cPWPd1MIFLSt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from datetime import datetime as dt\n",
        "from pprint import pprint as pp\n",
        "import matplotlib.dates as mdates\n",
        "import matplotlib.pyplot as plt\n",
        "import jhtalib as jhta\n",
        "\n",
        "\n",
        "def AR(df, n, price='Close'):\n",
        "\n",
        "  test1=jhta.COR([1, 2, 3, 4, 5, 6, 7, 8, 9],[0, 1, 2, 3, 4, 5, 6, 7, 8])\n",
        "  pp(test1)\n",
        "  end = len(df[price]) - n\n",
        "  x_list = list(range(len(df[price][0:end])))\n",
        "  y_list = df[price][0:end]\n",
        "  y1_list = df[price][1:end+1]\n",
        "  y2_list = df[price][2:end+2]\n",
        "  b1 = jhta.COV(x_list, y_list) / jhta.VARIANCE({'x': x_list}, len(x_list), 'x')[-1]\n",
        "  b0 = jhta.MEAN({'y': y_list}, len(y_list), 'y')[-1] - b1 * jhta.MEAN({'y': x_list}, len(x_list), 'x')[-1]\n",
        "  ar_dict = {'train': [], 'test': []}\n",
        "  print (jhta.COV(x_list, y_list))\n",
        "  print (jhta.VARIANCE({'x': x_list}, len(x_list), 'x')[-1])\n",
        "  print (jhta.MEAN({'x': x_list}, len(x_list), 'x')[-1])\n",
        "  print (jhta.MEAN({'y': y_list}, len(y_list), 'y')[-1])\n",
        "  print (b1)\n",
        "  print (b0)\n",
        "  i = 0\n",
        "  while i < len(df[price]):\n",
        "    y = b0 + b1 * i # Dit is OLS\n",
        "    if i < len(df[price]) - n:\n",
        "      ar_dict['train'].append(y)\n",
        "      ar_dict['test'].append(float('NaN'))\n",
        "    else:\n",
        "      ar_dict['train'].append(float('NaN'))\n",
        "      ar_dict['test'].append(y)\n",
        "    i += 1\n",
        "  return ar_dict\n",
        "\n",
        "def INERTIA(df):\n",
        "  \"\"\"\n",
        "  Inertia\n",
        "\n",
        "  source: https://www.fmlabs.com/reference/Inertia.htm\n",
        "  \"\"\"\n",
        "  \n",
        "x = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] #tijdschaal\n",
        "y = [0, 2, 1, 3, 2, 4, 3, 5, 4, 6] #input 'test' serie\n",
        "\n",
        "cor = jhta.COR(x, y)\n",
        "print (cor)\n",
        "pcor = jhta.PCOR(x, y)\n",
        "print (pcor)\n",
        "\n",
        "predictions_int = 0\n",
        "\n",
        "lsr_list = jhta.LSR({'y': y}, 'y', predictions_int)\n",
        "slr_list = jhta.SLR({'y': y}, 'y', predictions_int)\n",
        "\n",
        "n = 2\n",
        "\n",
        "#ar_dict = AR({'y': y}, n, 'y')\n",
        "\n",
        "y.extend([float('NaN')] * predictions_int)\n",
        "x = list(range(len(y)))\n",
        "\n",
        "print (lsr_list)\n",
        "print (slr_list)\n",
        "#print (ar_dict['train'])\n",
        "#print (ar_dict['test'])\n",
        "\n",
        "plt.figure(1, figsize=(30, 20))\n",
        "\n",
        "plt.subplot(311)\n",
        "plt.title('Time / Price / Ratio')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Price')\n",
        "plt.grid(True)\n",
        "plt.plot(x, y, color='blue')\n",
        "plt.plot(x, lsr_list, color='red')\n",
        "plt.legend(['Y', 'Least Squares Regression'], loc='upper left')\n",
        "#plt.yscale('log')\n",
        "\n",
        "plt.subplot(312)\n",
        "plt.title('Time / Price / Ratio')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Price')\n",
        "plt.grid(True)\n",
        "plt.plot(x, y, color='blue')\n",
        "plt.plot(x, slr_list, color='red')\n",
        "plt.legend(['Y', 'Simple Linear Regression'], loc='upper left')\n",
        "#plt.yscale('log')\n",
        "\n",
        "plt.subplot(313)\n",
        "plt.title('Time / Price / Ratio')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Price')\n",
        "plt.grid(True)\n",
        "plt.plot(x, y, color='blue')\n",
        "#plt.plot(x, ar_dict['train'], color='red')\n",
        "#plt.plot(x, ar_dict['test'], color='orange')\n",
        "plt.legend(['Y', 'AutoRegression'], loc='upper left')\n",
        "#plt.yscale('log')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kWOdpj3lmLs8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Candlestick\n",
        "source: http://www.candlestickforum.com/PPF/Parameters/16_263_/candlestick.asp\n",
        "source: https://www.tradingview.com/script/vcsWo8mh-Candlestick-Patterns-Identified-updated-3-11-15/\n",
        "source: https://www.tradeciety.com/understand-candlesticks-patterns/\n",
        "source: https://www.mql5.com/en/articles/5576\n",
        "source: https://www.mql5.com/en/articles/101\n",
        "source: https://www.ta-lib.org/hdr_dw.html for converting pattern recognition from C to Python3\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "xigjCRAq8u1n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install --upgrade jhtalib\n",
        "apikey = 'Apikey 9fa3addd7c29c1da3a51de2d10628c4d6c3747e2577c79ea047a85068708d66f'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0Hi_lTvBShex",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# http://www.candlestickforum.com/PPF/Parameters/16_263_/candlestick.asp\n",
        "# https://www.tradingview.com/script/vcsWo8mh-Candlestick-Patterns-Identified-updated-3-11-15/\n",
        "# https://www.tradeciety.com/understand-candlesticks-patterns/\n",
        "# https://www.mql5.com/en/articles/5576\n",
        "# https://www.mql5.com/en/articles/101\n",
        "# https://www.ta-lib.org/hdr_dw.html for converting pattern recognition from C to Python3\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import requests\n",
        "from datetime import datetime as dt\n",
        "from pprint import pprint as pp\n",
        "import matplotlib.dates as mdates\n",
        "import matplotlib.pyplot as plt\n",
        "import jhtalib as jhta\n",
        "\n",
        "\n",
        "url = 'https://min-api.cryptocompare.com/data/histoday?fsym=ETH&tsym=BTC&allData=true'\n",
        "headers = {'authorization': apikey}\n",
        "r = requests.get(url, headers=headers).json()\n",
        "#print (len(r['Data']))\n",
        "#pp (r)\n",
        "\n",
        "df = {'datetime': [], 'Open': [], 'High': [], 'Low': [], 'Close': [], 'Volume': []}\n",
        "i = 0\n",
        "while i < len(r['Data']):\n",
        "#  df['datetime'].append(i)\n",
        "#  df['datetime'].append(r['Data'][i]['time'])\n",
        "  df['datetime'].append(dt.fromtimestamp(r['Data'][i]['time']))\n",
        "  df['Open'].append(float(r['Data'][i]['open']))\n",
        "  df['High'].append(float(r['Data'][i]['high']))\n",
        "  df['Low'].append(float(r['Data'][i]['low']))\n",
        "  df['Close'].append(float(r['Data'][i]['close']))\n",
        "  df['Volume'].append(int(r['Data'][i]['volumefrom']))\n",
        "  i += 1\n",
        "\n",
        "jhta.DF2CSV(df, 'ETHBTC.csv')\n",
        "#jhta.INFO(df)\n",
        "\n",
        "\n",
        "def DOJI(df):\n",
        "  \"\"\"\n",
        "  Doji\n",
        "  \"\"\"\n",
        "  cdl_list = []\n",
        "  i = 0\n",
        "  while i < len(df['Close']):\n",
        "    o = df['Open'][i]\n",
        "    h = df['High'][i]\n",
        "    l = df['Low'][i]\n",
        "    c = df['Close'][i]\n",
        "\n",
        "    cdl = 0\n",
        "    \n",
        "#    if o == c:\n",
        "    if abs(o - c) <= (h - l) * .1:\n",
        "      cdl = 1\n",
        "\n",
        "    cdl_list.append(cdl)\n",
        "    i += 1\n",
        "  return cdl_list\n",
        "\n",
        "def ENGULFING(df):\n",
        "  \"\"\"\n",
        "  Engulfing\n",
        "  \"\"\"\n",
        "  cdl_list = []\n",
        "  i = 0\n",
        "  while i < len(df['Close']):\n",
        "    o = df['Open'][i]\n",
        "    h = df['High'][i]\n",
        "    l = df['Low'][i]\n",
        "    c = df['Close'][i]\n",
        "    o1 = df['Open'][i - 1]\n",
        "    h1 = df['High'][i - 1]\n",
        "    l1 = df['Low'][i - 1]\n",
        "    c1 = df['Close'][i - 1]\n",
        "    \n",
        "    cdl = 0\n",
        "    \n",
        "    # bullish:\n",
        "    if (o1 > c1) and (c > o) and (c >= o1) and (c1 >= o) and ((c - o) > (o1 - c1)):\n",
        "      cdl = 1\n",
        "    \n",
        "    # bearish:\n",
        "    if (c1 > o1) and (o > c) and (o >= c1) and (o1 >= c) and ((o - c) > (c1 - o1)):\n",
        "      cdl = -1\n",
        "    \n",
        "    cdl_list.append(cdl)\n",
        "    i += 1\n",
        "  return cdl_list\n",
        "\n",
        "def HAMMER(df):\n",
        "  \"\"\"\n",
        "  Hammer\n",
        "  \"\"\"\n",
        "  cdl_list = []\n",
        "  i = 0\n",
        "  while i < len(df['Close']):\n",
        "    o = df['Open'][i]\n",
        "    h = df['High'][i]\n",
        "    l = df['Low'][i]\n",
        "    c = df['Close'][i]\n",
        "    \n",
        "    cdl = 0\n",
        "    \n",
        "    # hammer:\n",
        "    if (h - l) > (3 * (o - c)) and ((c - l) / (.001 + h - l) > .6) and ((o - l) / (.001 + h - l) > .6):\n",
        "      cdl = 1\n",
        "    \n",
        "    # inverted hammer:\n",
        "    if (h - l) > (3 * (o - c)) and ((h - c) / (.001 + h - l) > .6) and ((h - o) / (.001 + h - l) > .6):\n",
        "      cdl = 1\n",
        "    \n",
        "    cdl_list.append(cdl)\n",
        "    i += 1\n",
        "  return cdl_list\n",
        "\n",
        "  \n",
        "#pp (df['Close'])\n",
        "#pp (jhta.RVI(df, 10))\n",
        "#pp (jhta.RMI(df, 10))\n",
        "#pp (DOJI(df))\n",
        "pp (ENGULFING(df))\n",
        "#pp (HAMMER(df))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "woklenS3dMpX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "  \n",
        "#Augmented Dickey Fuller stationair test\n",
        "  from statsmodels.tsa.stattools import adfuller\n",
        "  def test_stationarity(timeseries):\n",
        "\n",
        "#Determing rolling statistics\n",
        "      rolmean = pd.rolling_mean(timeseries, window=12)\n",
        "      rolstd = pd.rolling_std(timeseries, window=12)\n",
        "\n",
        "      #Plot rolling statistics:\n",
        "      orig = plt.plot(timeseries, color='blue',label='Original')\n",
        "      mean = plt.plot(rolmean, color='red', label='Rolling Mean')\n",
        "      std = plt.plot(rolstd, color='black', label = 'Rolling Std')\n",
        "      plt.legend(loc='best')\n",
        "      plt.title('Rolling Mean & Standard Deviation')\n",
        "      plt.show(block=False)\n",
        "\n",
        "      #Perform Dickey-Fuller test:\n",
        "      print 'Results of Dickey-Fuller Test:'\n",
        "      dftest = adfuller(timeseries, autolag='AIC')\n",
        "      dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n",
        "      for key,value in dftest[4].items():\n",
        "          dfoutput['Critical Value (%s)'%key] = value\n",
        "      print dfoutput\n",
        "  \n",
        "# Autocorrelation\n",
        "\n",
        "  def autocorrelation (x) :\n",
        "  \n",
        "    \"\"\"\n",
        "    Compute the autocorrelation of the signal, based on the properties of the\n",
        "    power spectral density of the signal.\n",
        "    \"\"\"\n",
        "    xp = x-np.mean(x)\n",
        "    f = np.fft.fft(xp)\n",
        "    p = np.array([np.real(v)**2+np.imag(v)**2 for v in f])\n",
        "    pi = np.fft.ifft(p)\n",
        "    return np.real(pi)[:x.size/2]/np.sum(xp**2)\n",
        "    \n",
        "Source: https://stackoverflow.com/questions/643699/how-can-i-use-numpy-correlate-to-do-autocorrelation\n",
        "\n"
      ]
    }
  ]
}